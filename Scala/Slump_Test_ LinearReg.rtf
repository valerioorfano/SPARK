{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf200
{\fonttbl\f0\fnil\fcharset0 Calibri;}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720

\f0\fs32 \cf0 import org.apache.spark.SparkContext._\
import org.apache.spark.mllib.regression.LabeledPoint;\
import org.apache.spark.mllib.feature.StandardScaler;\
import org.apache.spark.mllib.linalg.Vectors;\
import org.apache.spark.mllib.regression.LinearRegressionWithSGD;\
val sqlContext = new org.apache.spark.sql.SQLContext(sc);\
import sqlContext._ ;\
val data =sc.textFile("/home/tom/Desktop/slump_test.data");\
val header = data.first;\
val data2 = data.filter(x => x != header);\
val data3 = data2.map(_.split(",")).map(x => x.drop(1));\
case class Concrete(Cement: Double, Slag: Double, Fly_ash: Double, Water: Double, SP: Double, Coarse_Aggr: Double, Fine_Aggr: Double, SLUMP: Double, FLOW: Double, Mpa: Double);\
val concreteRDD = data3.map(x => Concrete(x(0).toDouble,x(1).toDouble,x(2).toDouble,x(3).toDouble,x(4).toDouble,x(5).toDouble,x(6).toDouble,x(7).toDouble,x(8).toDouble,x(9).toDouble));\
concreteRDD.registerAsTable("Concrete");\
val SLUMP = sqlContext.sql("select SLUMP,Cement,Slag,Fly_ash,Water,SP,Coarse_Aggr,Fine_Aggr from Concrete");\
val FLOW = sqlContext.sql("select FLOW,Cement,Slag,Fly_ash,Water,SP,Coarse_Aggr,Fine_Aggr from Concrete");\
val Mpa = sqlContext.sql("select Mpa,Cement,Slag,Fly_ash,Water,SP,Coarse_Aggr,Fine_Aggr from Concrete");\
val training_data = SLUMP.map\{row => \
val features = Array(row.getDouble(1),row.getDouble(2),row.getDouble(3),row.getDouble(4),row.getDouble(5),row.getDouble(6),row.getDouble(7))\
val label = row.getDouble(0)\
LabeledPoint(label, Vectors.dense(features))\} ;\
training_data.cache\
val scaler = new StandardScaler(withMean = true, withStd = true).fit(training_data.map(x => x.features));\
val scaledData = training_data.map(x => LabeledPoint(x.label, scaler.transform(Vectors.dense(x.features.toArray))));\
val numIterations = 100;\
val step = 0.2\
val model = LinearRegressionWithSGD.train(scaledData, numIterations, step);\
val Predictions = scaledData.map\{x => \
val predict = model.predict(x.features)\
(x.label, predict)\};\
val mse = Predictions.map\{case (l,p) => math.pow((l - p), 2)\}.mean()\
println ("Mean Squared Error: "+ mse)}